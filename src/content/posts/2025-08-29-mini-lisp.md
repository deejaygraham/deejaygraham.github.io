---
title: Mini Lisp
tags: [tdd, code, python]
---

This is probably something I should have attempted many years ago when I was first introduced to "Structure and Interpretation of Computer Programs" by Abelson and Sussman and the 
recorded lecture series. Anyway, since I didn't do it then, here is a small implementation of Lisp in Python. I had intended originally for it to be super minimal so it could run 
on the microbit, just for fun, but I got a bit too carried away with it and it got too big. Maybe I will retry it to be more like something that would fit on that device later.

The code has been split up into several sections/files but the unit tests driving it have been kept within one giant class just for convenience when writing it. 


## Unit Tests

```python
import unittest

class TestLispEvaluation(unittest.TestCase):

	def test_tokenize_splits_list_into_tokens(self):
		code = "(+ 1 2 3)"
		tokens = tokenize(code)
		self.assertEqual(tokens, ["(", "+", "1", "2", "3", ")"])

	def test_parse_splits_list_into_operator_and_numbers(self):
		tokens = ["(", "+", "1", "2", "3", ")"]
		expression = parse(tokens)
		self.assertEqual(expression, ["+", 1, 2, 3])

	def test_parse_splits_nested_lists(self):
		code = "(+ 1 (+ 2 3))"
		expression = parse(tokenize(code))
		self.assertEqual(expression, ["+", 1, ["+", 2, 3]])

	def test_evaluate_addition_of_three_numbers(self):
		code = "(+ 1 2 9)"
		expression = parse(tokenize(code))
		self.assertEqual(evaluate(expression), 12)

	def test_evaluate_nested_addtions(self):
		code = "(+ 1 (+ 2 3) 4)"
		expression = parse(tokenize(code))
		self.assertEqual(evaluate(expression), 10)

	def test_negation_operator(self):
		self.assertEqual(evaluate(parse(tokenize("(- 5)"))), -5)
		self.assertEqual(evaluate(parse(tokenize("(- 10 3 2)"))), 5)

	def test_multiplication(self):
		self.assertEqual(evaluate(parse(tokenize("(* 2 3 4)"))), 24)

	def test_division(self):
		self.assertEqual(evaluate(parse(tokenize("(/ 8 2 2)"))), 2)
		self.assertEqual(evaluate(parse(tokenize("(/ 4)"))), 0.25)

	def test_equality(self):
		self.assertTrue(evaluate(parse(tokenize("(= 3 3 3)"))))
		self.assertFalse(evaluate(parse(tokenize("(= 3 4)"))))

	def test_less_than(self):
		self.assertTrue(evaluate(parse(tokenize("(< 1 2 3)"))))
		self.assertFalse(evaluate(parse(tokenize("(< 1 1 2)"))))

	def test_greater_than(self):
		self.assertTrue(evaluate(parse(tokenize("(> 3 2 1)"))))
		self.assertFalse(evaluate(parse(tokenize("(> 3 3 2)"))))

	def test_if_true_branch(self):
		self.assertEqual(evaluate(parse(tokenize("(if (= 1 1) 42 0)"))), 42)

	def test_if_false_branch(self):
		self.assertEqual(evaluate(parse(tokenize("(if (= 1 2) 42 0)"))), 0)

	def test_if_no_alt_returns_none(self):
		self.assertIsNone(evaluate(parse(tokenize("(if (= 1 2) 42)"))))

	def test_if_lazy_evaluation(self):
		self.assertEqual(evaluate(parse(tokenize("(if (= 1 1) 1 (/ 1 0))"))), 1)
		self.assertEqual(evaluate(parse(tokenize("(if (= 1 2) (/ 1 0) 2)"))), 2)

	def test_if_too_few_arguments_errors(self):
		with self.assertRaises(SyntaxError):
			evaluate(parse(tokenize("(if)")))
		with self.assertRaises(SyntaxError):
			evaluate(parse(tokenize("(if 1)")))

	def test_if_too_many_arguments_errors(self):
		with self.assertRaises(SyntaxError):
			evaluate(parse(tokenize("(if 1 2 3 4)")))

	def test_lambda_simple_call(self):
		self.assertEqual(evaluate(parse(tokenize("((lambda (x) (+ x 1)) 5)"))), 6)

	def test_define_function_and_call(self):
		code = "(define inc (lambda (x) (+ x 1)))"
		env = standard_env()
		evaluate(parse(tokenize(code)), env)
		self.assertEqual(evaluate(parse(tokenize("(inc 10)")), env), 11)

	def test_lambda_closure_captures_environment(self):
		global_scope = standard_env()
		env = Environment({"y": 3}, parent=global_scope)
		fn = evaluate(parse(tokenize("(lambda (x) (+ x y))")), env)
		self.assertEqual(fn(7), 10)

	def test_lambda_arity_errors(self):
		with self.assertRaises(TypeError):
			evaluate(parse(tokenize("((lambda (x y) x) 1)")))
		with self.assertRaises(TypeError):
			evaluate(parse(tokenize("((lambda () 1) 2)")))

	def test_quote_returns_expression_unevaluated(self):
		self.assertEqual(evaluate(parse(tokenize("(quote (1 2 3))"))), [1, 2, 3])

	def test_comments_are_ignored(self):
		self.assertEqual(tokenize("(list 1 ; comment here\n 2 3)"), ["(", "list", "1", "2", "3", ")"])

	def test_string_literals_and_escapes(self):
		self.assertEqual(evaluate(parse(tokenize('"hi"'))), "hi")
		self.assertEqual(evaluate(parse(tokenize('"a\\n b"'))), "a\n b")
		self.assertEqual(evaluate(parse(tokenize('"a\\t\\"b\\""'))), 'a\t"b"')

	def test_begin_evaluates_in_sequence_and_returns_last(self):
		env = standard_env()
		expression = parse(tokenize("(begin (define x 1) (define y 2) (+ x y))"))
		self.assertEqual(evaluate(expression, env), 3)

	def test_list_primitives(self):
		self.assertEqual(evaluate(parse(tokenize("(list 1 2 3)"))), [1, 2, 3])
		self.assertEqual(evaluate(parse(tokenize("(car (list 4 5))"))), 4)
		self.assertEqual(evaluate(parse(tokenize("(cdr (list 4 5 6))"))), [5, 6])
		self.assertTrue(evaluate(parse(tokenize("(null? (list))"))))
		self.assertFalse(evaluate(parse(tokenize("(null? (list 1))"))))
		self.assertEqual(evaluate(parse(tokenize("(cons 1 (list 2 3))"))), [1, 2, 3])

	def test_boolean_literals(self):
		self.assertTrue(evaluate(parse(tokenize("true"))))
		self.assertFalse(evaluate(parse(tokenize("false"))))
		self.assertTrue(evaluate(parse(tokenize("#t"))))
		self.assertFalse(evaluate(parse(tokenize("#f"))))

	def test_not_and_or(self):
		self.assertFalse(evaluate(parse(tokenize("(not true)"))))
		self.assertTrue(evaluate(parse(tokenize("(not false)"))))
		self.assertTrue(evaluate(parse(tokenize("(and true true)"))))
		self.assertFalse(evaluate(parse(tokenize("(and true false)"))))
		self.assertTrue(evaluate(parse(tokenize("(or false true)"))))
		self.assertFalse(evaluate(parse(tokenize("(or false false)"))))

	def test_and_or_short_circuit(self):
		# right side should not evaluate when unnecessary
		self.assertEqual(evaluate(parse(tokenize("(and true 1)"))), 1)
		self.assertFalse(evaluate(parse(tokenize("(and false (/ 1 0))"))))
		self.assertTrue(evaluate(parse(tokenize("(or true (/ 1 0))"))))

	def test_errors_empty_list(self):
		with self.assertRaises(ValueError):
			evaluate([])

	def test_errors_unknown_symbol(self):
		with self.assertRaises(NameError):
			evaluate(parse(tokenize("(unknown 1 2)")))

	def test_errors_malformed_define(self):
		with self.assertRaises(SyntaxError):
			evaluate(parse(tokenize("(define 1 2)")))
		with self.assertRaises(SyntaxError):
			evaluate(parse(tokenize("(define x)")))

	def test_errors_sub_zero_arity(self):
		with self.assertRaises(TypeError):
			evaluate(parse(tokenize("(-)")))

	def test_errors_div_zero_arity(self):
		with self.assertRaises(TypeError):
			evaluate(parse(tokenize("(/)")))

	def test_errors_division_by_zero(self):
		with self.assertRaises(ZeroDivisionError):
			evaluate(parse(tokenize("(/ 1 0)")))

	def test_define_binds_variable_in_environment(self):
		code = "(define x 7)"
		env = Environment()
		expression = parse(tokenize(code))
		self.assertEqual(evaluate(expression, env), 7)
		self.assertEqual(evaluate("x", env), 7)

	def test_errors_unexpected_end(self):
		with self.assertRaises(SyntaxError):
			parse(["(", "+", "1"])  # missing ')'

	def test_errors_extra_input(self):
		with self.assertRaises(SyntaxError):
			parse(["1", "2"])  # two top-level expressions

	def test_value_found_in_parent_scope_if_not_in_local(self):
		parent = Environment({"x": 42})
		child = Environment({"y": 100}, parent=parent)
		self.assertEqual(child["x"], 42)
		self.assertEqual(child.get("x"), 42)
		self.assertEqual(child.get("z", None), None)
		with self.assertRaises(KeyError):
			_ = child["z"]


if __name__ == "__main__":
	unittest.main()

```

Rather long but I wanted to capture as much of the full language behaviour in one place.


## Code

First off we have the traditional lexer which takes the source text and creates a list of tokens for onward processing.

### lexer.py

```python
from __future__ import annotations
from typing import List


def tokenize(source: str) -> List[str]:
	"""Convert a Lisp source string into a list of tokens.

	Supports:
	- parentheses as separate tokens
	- string literals with escapes (" \\ \n \t)
	- comments starting with ';' to end of line
	"""
	result: List[str] = []
	buf: List[str] = []
	in_string = False
	escaping = False

	def flush_buf():
		if buf:
			result.append(''.join(buf))
			buf.clear()

	i = 0
	while i < len(source):
		ch = source[i]
		if in_string:
			if escaping:
				if ch == 'n':
					buf.append('\n')
				elif ch == 't':
					buf.append('\t')
				else:
					buf.append(ch)
				escaping = False
				i += 1
				continue
			if ch == '\\':
				escaping = True
				i += 1
				continue
			if ch == '"':
				# close string
				result.append('"' + ''.join(buf) + '"')
				buf.clear()
				in_string = False
				i += 1
				continue
			buf.append(ch)
			i += 1
			continue

		# not in string
		if ch == ';':
			# comment to end of line
			flush_buf()
			while i < len(source) and source[i] != '\n':
				i += 1
			continue
		if ch == '"':
			flush_buf()
			in_string = True
			i += 1
			continue
		if ch in ('(', ')'):
			flush_buf()
			result.append(ch)
			i += 1
			continue
		if ch.isspace():
			flush_buf()
			i += 1
			continue
		buf.append(ch)
		i += 1

	flush_buf()
	return result

```

Next we need to create an abstract syntax tree from the list of tokens and we do that in a parser

### parser.py

```python
from __future__ import annotations
from typing import Any, List, Union
from .lexer import tokenize


class Symbol(str):
	"""Represents a symbol (identifier) distinct from string literals."""
	pass


class String(str):
	"""Represents a string literal distinct from symbols."""
	pass


Atom = Union[int, float, bool, Symbol, String, str]
Expression = Union[Atom, List["Expression"]]


def parse(tokens: List[str]) -> Expression:
	"""Parse a list of tokens into a nested Python structure."""
	def parse_expr(position: int = 0) -> tuple[Expression, int]:
		if position >= len(tokens):
			raise SyntaxError("Unexpected end of input")

		tok = tokens[position]
		if tok == "(":
			lst: List[Expression] = []
			position += 1
			while position < len(tokens) and tokens[position] != ")":
				elem, position = parse_expr(position)
				lst.append(elem)
			if position >= len(tokens) or tokens[position] != ")":
				raise SyntaxError("Missing closing parenthesis")
			return lst, position + 1
		elif tok == ")":
			raise SyntaxError("Unexpected )")

		return atom(tok), position + 1

	expr, next_pos = parse_expr(0)
	if next_pos != len(tokens):
		raise SyntaxError("Extra input after expression")
	return expr


def atom(token: str) -> Atom:
	"""Convert token to int, float, boolean, string literal, or symbol."""
	# booleans
	if token in ("true", "#t"):
		return True
	if token in ("false", "#f"):
		return False
	# string literal
	if len(token) >= 2 and token[0] == '"' and token[-1] == '"':
		return String(token[1:-1])
	try:
		return int(token)
	except ValueError:
		pass
	# float
	try:
		return float(token)
	except ValueError:
		pass
	# symbol
	return Symbol(token)

```

An evaluator is the heart of the language and takes the output of the parser and actually tries to do something with it.

### evaluator.py

```python

from __future__ import annotations
from typing import Any, List, Union, Callable
from .environment import Environment
from .parser import Symbol, String, Expression
from .special_forms import create_special_forms
from .truth import is_truthy

def standard_env() -> Environment:
	env: Environment = Environment()
	# Core operations
	def _sub(*args: float) -> float:
		if len(args) == 0:
			raise TypeError("- expects at least 1 argument")
		if len(args) == 1:
			return -args[0]
		result = args[0]
		for value in args[1:]:
			result -= value
		return result

	def _mul(*args: float) -> float:
		result: float = 1
		for value in args:
			result *= value
		return result

	def _div(*args: float) -> float:
		if len(args) == 0:
			raise TypeError("/ expects at least 1 argument")
		if len(args) == 1:
			return 1 / args[0]
		result = args[0]
		for value in args[1:]:
			result /= value
		return result

	def _eq(*args: float) -> bool:
		if len(args) < 2:
			return True
		first = args[0]
		return all(value == first for value in args[1:])

	def _lt(*args: float) -> bool:
		return all(a < b for a, b in zip(args, args[1:]))

	def _gt(*args: float) -> bool:
		return all(a > b for a, b in zip(args, args[1:]))

	env.update({
		"+": lambda *args: sum(args),
		"-": _sub,
		"*": _mul,
		"/": _div,
		"=": _eq,
		"<": _lt,
		">": _gt,
		"not": lambda v: not is_truthy(v),
		"list": lambda *args: list(args),
		"cons": lambda a, d: [a] + (d if isinstance(d, list) else [d]),
		"car": lambda lst: lst[0],
		"cdr": lambda lst: lst[1:],
		"null?": lambda lst: (len(lst) == 0),
	})
	return env


def evaluate(x: Expression, env: Environment | None = None) -> Any:
	"""Evaluate an expression in the given environment.

	Supports:
	- numbers
	- (+ x y ...)
	"""
	if env is None:
		env = standard_env()

	# atom
	if isinstance(x, (int, float, bool)):
		return x
	# String literal evaluates to itself
	if isinstance(x, String):
		return str(x)
	# Symbols or raw strings lookup
	if isinstance(x, (Symbol, str)):
		return env[x]

	# list expression
	if not x:
		raise ValueError("Cannot evaluate empty list")

	op_expr = x[0]

	# Centralized special-form dispatch
	def sf_define(expr: list[Any], env: Environment) -> Any:
		if len(expr) != 3 or not isinstance(expr[1], str):
			raise SyntaxError("(define name expr) expected")
		name = expr[1]
		value = evaluate(expr[2], env)
		env[name] = value
		return value

	def sf_if(expr: list[Any], env: Environment) -> Any:
		if len(expr) not in (3, 4):
			raise SyntaxError("(if test conseq [alt]) expected")
		test_expr = expr[1]
		conseq_expr = expr[2]
		alt_expr = expr[3] if len(expr) == 4 else None
		condition = evaluate(test_expr, env)
		if is_truthy(condition):
			return evaluate(conseq_expr, env)
		
		return evaluate(alt_expr, env) if alt_expr is not None else None

	def sf_quote(expr: list[Any], env: Environment) -> Any:
		if len(expr) != 2:
			raise SyntaxError("(quote expr) expected")
		return expr[1]

	def sf_begin(expr: list[Any], env: Environment) -> Any:
		if len(expr) < 2:
			raise SyntaxError("(begin expr ...) expected")
		result: Any = None
		for sub in expr[1:]:
			result = evaluate(sub, env)
		return result

	def sf_and(expr: list[Any], env: Environment) -> Any:
		if len(expr) < 2:
			raise SyntaxError("(and expr ...) expected")
		result: Any = True
		for sub in expr[1:]:
			result = evaluate(sub, env)
			if not is_truthy(result):
				return False
		return result

	def sf_or(expr: list[Any], env: Environment) -> Any:
		if len(expr) < 2:
			raise SyntaxError("(or expr ...) expected")
		for sub in expr[1:]:
			val = evaluate(sub, env)
			if is_truthy(val):
				return val
		return False

	def sf_lambda(expr: list[Any], env: Environment) -> Any:
		if len(expr) != 3 or not isinstance(expr[1], list):
			raise SyntaxError("(lambda (params) body) expected")
		params = expr[1]
		if not all(isinstance(p, str) for p in params):
			raise SyntaxError("lambda params must be symbols")
		body = expr[2]
		closure_env = env

		def procedure(*args: Any) -> Any:
			if len(args) != len(params):
				raise TypeError("lambda arity mismatch")
			bindings = {name: value for name, value in zip(params, args)}
			call_env = Environment(bindings, parent=closure_env)
			return evaluate(body, call_env)

		return procedure

	SPECIAL_FORMS: dict[str, Callable[[list[Any], Environment], Any]] = {
		"define": sf_define,
		"if": sf_if,
		"quote": sf_quote,
		"begin": sf_begin,
		"and": sf_and,
		"or": sf_or,
		"lambda": sf_lambda,
	}

	# Build dispatch lazily to avoid import cycle; pass evaluate closure
	SPECIAL_FORMS = create_special_forms(evaluate)
	if isinstance(op_expr, (str, Symbol)) and str(op_expr) in SPECIAL_FORMS:
		return SPECIAL_FORMS[str(op_expr)](x, env)

	proc = evaluate(op_expr, env) if isinstance(op_expr, list) else env.get(op_expr, None) if isinstance(op_expr, (str, Symbol)) else op_expr
	if proc is None:
		raise NameError(f"Unknown symbol: {op_expr}")

	args = [evaluate(arg, env) for arg in x[1:]]
	if callable(proc):
		return proc(*args)

	return [proc] + args  

```

Of course there are a lot of support functions around the evaluator that need to be included.

An execution environment or context lets us support symbols in nested scopes.

### environment.py

```python
from __future__ import annotations
from typing import Any


class Environment:
	"""
	An environment mapping symbols to values using an internal scope dict.
	Supports lexical scoping via an optional parent environment.
	"""

	def __init__(self, initial: dict[str, Any] | None = None, parent: "Environment | None" = None) -> None:
		self.scope: dict[str, Any] = {} if initial is None else dict(initial)
		self.parent: Environment | None = parent

	def __getitem__(self, key: str) -> Any:
		""" Indexer forces value to exist in this scope or parent scope. Throws KeyError if not found."""
		if key in self.scope:
			return self.scope[key]
		if self.parent is not None:
			return self.parent[key]
		raise KeyError(key)

	def __setitem__(self, key: str, value: Any) -> None:
		""" Set binding in this scope."""
		self.scope[key] = value

	def get(self, key: str, default: Any = None) -> Any:
		""" Maybe value exists in this scope or parent scope. Returns default if not found."""
		if key in self.scope:
			return self.scope[key]
		if self.parent is not None:
			return self.parent.get(key, default)
		return default

	def update(self, other: dict[str, Any]) -> None:
		self.scope.update(other)

```

Procedure evalutation for user-defined procedures

### procedure.py

```python
from __future__ import annotations
from typing import Any, List, Callable
from .environment import Environment

class Procedure:
	"""Callable user-defined procedure with lexical closure."""

	def __init__(self, params: List[str], body: Any, closure_env: Environment, eval_fn: Callable[[Any, Environment], Any]) -> None:
		self.params = params
		self.body = body
		self.closure_env = closure_env
		self._evaluate = eval_fn

	def __call__(self, *args: Any) -> Any:
		if len(args) != len(self.params):
			raise TypeError("lambda arity mismatch")
		bindings = {name: value for name, value in zip(self.params, args)}
		call_env = Environment(bindings, parent=self.closure_env)
		return self._evaluate(self.body, call_env)

	def __repr__(self) -> str:
		params_str = " ".join(self.params)
		return f"<procedure (lambda ({params_str}) …)>"

```

A simple truthy function used by a couple of files so moved into a utility file

### truth.py

```python
from __future__ import annotations

def is_truthy(value: object) -> bool:
	"""Centralized truthiness rule.
	Currently mirrors Python truthiness. Adjust here for language semantics.
	"""
	return bool(value)

```

Special forms in Lisp are handling for things like defines, conditions, lambda etc. In a separate file here for addition later if required.

### special_forms.py

```python
from __future__ import annotations
from typing import Any, Callable
from .environment import Environment
from .parser import Symbol
from typing import Callable as _Callable
from .truth import is_truthy
from .procedure import Procedure


def sf_define(expr: list[Any], env: Environment, evaluate: _Callable[[Any, Environment], Any]) -> Any:
	if len(expr) != 3 or not isinstance(expr[1], str):
		raise SyntaxError("(define name expr) expected")
	name = expr[1]
	value = evaluate(expr[2], env)
	env[name] = value
	return value


def sf_if(expr: list[Any], env: Environment, evaluate: _Callable[[Any, Environment], Any]) -> Any:
	if len(expr) not in (3, 4):
		raise SyntaxError("(if test conseq [alt]) expected")
	test_expr = expr[1]
	conseq_expr = expr[2]
	alt_expr = expr[3] if len(expr) == 4 else None
	condition = evaluate(test_expr, env)
	if is_truthy(condition):
		return evaluate(conseq_expr, env)

	return evaluate(alt_expr, env) if alt_expr is not None else None

def sf_quote(expr: list[Any], env: Environment, evaluate: _Callable[[Any, Environment], Any]) -> Any:
	if len(expr) != 2:
		raise SyntaxError("(quote expr) expected")
	return expr[1]

def sf_begin(expr: list[Any], env: Environment, evaluate: _Callable[[Any, Environment], Any]) -> Any:
	if len(expr) < 2:
		raise SyntaxError("(begin expr ...) expected")
	result: Any = None
	for sub in expr[1:]:
		result = evaluate(sub, env)
	return result

def sf_and(expr: list[Any], env: Environment, evaluate: _Callable[[Any, Environment], Any]) -> Any:
	if len(expr) < 2:
		raise SyntaxError("(and expr ...) expected")
	result: Any = True
	for sub in expr[1:]:
		result = evaluate(sub, env)
		if not is_truthy(result):
			return False
	return result

def sf_or(expr: list[Any], env: Environment, evaluate: _Callable[[Any, Environment], Any]) -> Any:
	if len(expr) < 2:
		raise SyntaxError("(or expr ...) expected")
	for sub in expr[1:]:
		val = evaluate(sub, env)
		if is_truthy(val):
			return val
	return False

def sf_lambda(expr: list[Any], env: Environment, evaluate: _Callable[[Any, Environment], Any]) -> Any:
	if len(expr) != 3 or not isinstance(expr[1], list):
		raise SyntaxError("(lambda (params) body) expected")
	params = expr[1]
	if not all(isinstance(p, str) for p in params):
		raise SyntaxError("lambda params must be symbols")
	body = expr[2]
	closure_env = env
	return Procedure(params, body, closure_env, evaluate)

def create_special_forms(evaluate: _Callable[[Any, Environment], Any]) -> dict[str, Callable[[list[Any], Environment], Any]]:
	return {
		"define": lambda expr, env: sf_define(expr, env, evaluate),
		"if": lambda expr, env: sf_if(expr, env, evaluate),
		"quote": lambda expr, env: sf_quote(expr, env, evaluate),
		"begin": lambda expr, env: sf_begin(expr, env, evaluate),
		"and": lambda expr, env: sf_and(expr, env, evaluate),
		"or": lambda expr, env: sf_or(expr, env, evaluate),
		"lambda": lambda expr, env: sf_lambda(expr, env, evaluate),
	}

```

## Repl

What language would be complete without a tiny repl to interact with the language? This isn't a substitute for running the tests
but helps in adhoc exploration.

### repl.py

```python
from __future__ import annotations
from .lexer import tokenize
from .parser import parse
from .evaluator import evaluate, standard_env

def repl():
	env = standard_env()
	buffer = ""
	primary, cont = "lisp> ", "...> "

	def paren_balance(s: str) -> int:
		open_count = s.count("(")
		close_count = s.count(")")
		return open_count - close_count

	prompt = primary
	while True:
		try:
			line = input(prompt)
		except (EOFError, KeyboardInterrupt):
			print()
			break

		buffer += ("\n" if buffer else "") + line
		balanced = paren_balance(buffer)
		if balanced > 0:
			prompt = cont
			continue
		elif balanced < 0:
      		# John McCarthy said to ensure a program definitely ends, add a few closing parens to at least trigger an error. 
			print("SyntaxError: too many ')'")
			buffer = ""
			prompt = primary
			continue

		if not buffer.strip():
			prompt = primary
			continue

		try:
			expr = parse(tokenize(buffer))
			result = evaluate(expr, env)
			if result is not None:
				print(result)
		except Exception as e:
			print(f"Error: {e}")
		finally:
			buffer = ""
			prompt = primary


if __name__ == "__main__":
	repl()

```
